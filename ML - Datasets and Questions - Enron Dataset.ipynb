{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a person of interest?\n",
    "* Indicted\n",
    "* Settled without admitting guilt\n",
    "* Testified in exchange for Immunity\n",
    "\n",
    "### Accuracy <=> Training Set Size\n",
    "* MORE DATA > FINE TUNED ALGORITHM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    Starter code for exploring the Enron dataset (emails + finances);\n",
    "    loads up the dataset (pickled dict of dicts).\n",
    "\n",
    "    The dataset has the form:\n",
    "    enron_data[\"LASTNAME FIRSTNAME MIDDLEINITIAL\"] = { features_dict }\n",
    "\n",
    "    {features_dict} is a dictionary of features associated with that person.\n",
    "    You should explore features_dict as part of the mini-project,\n",
    "    but here's an example to get you started:\n",
    "\n",
    "    enron_data[\"SKILLING JEFFREY K\"][\"bonus\"] = 5600000\n",
    "    \n",
    "\"\"\"\n",
    "\n",
    "import pickle\n",
    "\n",
    "enron_data = pickle.load(open(\"C:/Users/nmeli/Documents/Udacity/Data Analysis/Notebooks/Machine Learning/ud120-projects/final_project/final_project_dataset.pkl\", \"r\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5600000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_data[\"SKILLING JEFFREY K\"][\"bonus\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 5600000,\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': 'NaN',\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'jeff.skilling@enron.com',\n",
       " 'exercised_stock_options': 19250000,\n",
       " 'expenses': 29336,\n",
       " 'from_messages': 108,\n",
       " 'from_poi_to_this_person': 88,\n",
       " 'from_this_person_to_poi': 30,\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 1920000,\n",
       " 'other': 22122,\n",
       " 'poi': True,\n",
       " 'restricted_stock': 6843672,\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 1111258,\n",
       " 'shared_receipt_with_poi': 2042,\n",
       " 'to_messages': 3627,\n",
       " 'total_payments': 8682716,\n",
       " 'total_stock_value': 26093672}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_data[\"SKILLING JEFFREY K\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many data points(people) are in the dataset?\n",
    "len(enron_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METTS MARK\n",
      "BAXTER JOHN C\n",
      "ELLIOTT STEVEN\n",
      "CORDES WILLIAM R\n",
      "HANNON KEVIN P\n",
      "MORDAUNT KRISTINA M\n",
      "MEYER ROCKFORD G\n",
      "MCMAHON JEFFREY\n",
      "HORTON STANLEY C\n",
      "PIPER GREGORY F\n",
      "HUMPHREY GENE E\n",
      "UMANOFF ADAM S\n",
      "BLACHMAN JEREMY M\n",
      "SUNDE MARTIN\n",
      "GIBBS DANA R\n",
      "LOWRY CHARLES P\n",
      "COLWELL WESLEY\n",
      "MULLER MARK S\n",
      "JACKSON CHARLENE R\n",
      "WESTFAHL RICHARD K\n",
      "WALTERS GARETH W\n",
      "WALLS JR ROBERT H\n",
      "KITCHEN LOUISE\n",
      "CHAN RONNIE\n",
      "BELFER ROBERT\n",
      "SHANKMAN JEFFREY A\n",
      "WODRASKA JOHN\n",
      "BERGSIEKER RICHARD P\n",
      "URQUHART JOHN A\n",
      "BIBI PHILIPPE A\n",
      "RIEKER PAULA H\n",
      "WHALEY DAVID A\n",
      "BECK SALLY W\n",
      "HAUG DAVID L\n",
      "ECHOLS JOHN B\n",
      "MENDELSOHN JOHN\n",
      "HICKERSON GARY J\n",
      "CLINE KENNETH W\n",
      "LEWIS RICHARD\n",
      "HAYES ROBERT E\n",
      "MCCARTY DANNY J\n",
      "KOPPER MICHAEL J\n",
      "LEFF DANIEL P\n",
      "LAVORATO JOHN J\n",
      "BERBERIAN DAVID\n",
      "DETMERING TIMOTHY J\n",
      "WAKEHAM JOHN\n",
      "POWERS WILLIAM\n",
      "GOLD JOSEPH\n",
      "BANNANTINE JAMES M\n",
      "DUNCAN JOHN H\n",
      "SHAPIRO RICHARD S\n",
      "SHERRIFF JOHN R\n",
      "SHELBY REX\n",
      "LEMAISTRE CHARLES\n",
      "DEFFNER JOSEPH M\n",
      "KISHKILL JOSEPH G\n",
      "WHALLEY LAWRENCE G\n",
      "MCCONNELL MICHAEL S\n",
      "PIRO JIM\n",
      "DELAINEY DAVID W\n",
      "SULLIVAN-SHAKLOVITZ COLLEEN\n",
      "WROBEL BRUCE\n",
      "LINDHOLM TOD A\n",
      "MEYER JEROME J\n",
      "LAY KENNETH L\n",
      "BUTTS ROBERT H\n",
      "OLSON CINDY K\n",
      "MCDONALD REBECCA\n",
      "CUMBERLAND MICHAEL S\n",
      "GAHN ROBERT S\n",
      "MCCLELLAN GEORGE\n",
      "HERMANN ROBERT J\n",
      "SCRIMSHAW MATTHEW\n",
      "GATHMANN WILLIAM D\n",
      "HAEDICKE MARK E\n",
      "BOWEN JR RAYMOND M\n",
      "GILLIS JOHN\n",
      "FITZGERALD JAY L\n",
      "MORAN MICHAEL P\n",
      "REDMOND BRIAN L\n",
      "BAZELIDES PHILIP J\n",
      "BELDEN TIMOTHY N\n",
      "DURAN WILLIAM D\n",
      "THORN TERENCE H\n",
      "FASTOW ANDREW S\n",
      "FOY JOE\n",
      "CALGER CHRISTOPHER F\n",
      "RICE KENNETH D\n",
      "KAMINSKI WINCENTY J\n",
      "LOCKHART EUGENE E\n",
      "COX DAVID\n",
      "OVERDYKE JR JERE C\n",
      "PEREIRA PAULO V. FERRAZ\n",
      "STABLER FRANK\n",
      "SKILLING JEFFREY K\n",
      "BLAKE JR. NORMAN P\n",
      "SHERRICK JEFFREY B\n",
      "PRENTICE JAMES\n",
      "GRAY RODNEY\n",
      "PICKERING MARK R\n",
      "THE TRAVEL AGENCY IN THE PARK\n",
      "NOLES JAMES L\n",
      "KEAN STEVEN J\n",
      "TOTAL\n",
      "FOWLER PEGGY\n",
      "WASAFF GEORGE\n",
      "WHITE JR THOMAS E\n",
      "CHRISTODOULOU DIOMEDES\n",
      "ALLEN PHILLIP K\n",
      "SHARP VICTORIA T\n",
      "JAEDICKE ROBERT\n",
      "WINOKUR JR. HERBERT S\n",
      "BROWN MICHAEL\n",
      "BADUM JAMES P\n",
      "HUGHES JAMES A\n",
      "REYNOLDS LAWRENCE\n",
      "DIMICHELE RICHARD G\n",
      "BHATNAGAR SANJAY\n",
      "CARTER REBECCA C\n",
      "BUCHANAN HAROLD G\n",
      "YEAP SOON\n",
      "MURRAY JULIA H\n",
      "GARLAND C KEVIN\n",
      "DODSON KEITH\n",
      "YEAGER F SCOTT\n",
      "HIRKO JOSEPH\n",
      "DIETRICH JANET R\n",
      "DERRICK JR. JAMES V\n",
      "FREVERT MARK A\n",
      "PAI LOU L\n",
      "BAY FRANKLIN R\n",
      "HAYSLETT RODERICK J\n",
      "FUGH JOHN L\n",
      "FALLON JAMES B\n",
      "KOENIG MARK E\n",
      "SAVAGE FRANK\n",
      "IZZO LAWRENCE L\n",
      "TILNEY ELIZABETH A\n",
      "MARTIN AMANDA K\n",
      "BUY RICHARD B\n",
      "GRAMM WENDY L\n",
      "CAUSEY RICHARD A\n",
      "TAYLOR MITCHELL S\n",
      "DONAHUE JR JEFFREY M\n",
      "GLISAN JR BEN F\n"
     ]
    }
   ],
   "source": [
    "for n in enron_data:\n",
    "    print n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "# For each person, how many features are available?\n",
    "for k,v in enron_data.items():\n",
    "    print(len(v.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "# How many POIs are there in the E+F dataset\n",
    "count = 0\n",
    "for p in enron_data:\n",
    "    for i in enron_data[p]:\n",
    "        if i == \"poi\":\n",
    "            if enron_data[p][i] == 1:\n",
    "                count +=1\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1095040"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the total value of the stock belonging to James Prentice?\n",
    "enron_data[\"PRENTICE JAMES\"]['total_stock_value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 1200000,\n",
       " 'deferral_payments': 27610,\n",
       " 'deferred_income': -144062,\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'wes.colwell@enron.com',\n",
       " 'exercised_stock_options': 'NaN',\n",
       " 'expenses': 16514,\n",
       " 'from_messages': 40,\n",
       " 'from_poi_to_this_person': 240,\n",
       " 'from_this_person_to_poi': 11,\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 'NaN',\n",
       " 'other': 101740,\n",
       " 'poi': True,\n",
       " 'restricted_stock': 698242,\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 288542,\n",
       " 'shared_receipt_with_poi': 1132,\n",
       " 'to_messages': 1758,\n",
       " 'total_payments': 1490344,\n",
       " 'total_stock_value': 698242}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How many email messages do we have from Wesley Colwell to persons of interest?\n",
    "enron_data[\"COLWELL WESLEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bonus': 5600000,\n",
       " 'deferral_payments': 'NaN',\n",
       " 'deferred_income': 'NaN',\n",
       " 'director_fees': 'NaN',\n",
       " 'email_address': 'jeff.skilling@enron.com',\n",
       " 'exercised_stock_options': 19250000,\n",
       " 'expenses': 29336,\n",
       " 'from_messages': 108,\n",
       " 'from_poi_to_this_person': 88,\n",
       " 'from_this_person_to_poi': 30,\n",
       " 'loan_advances': 'NaN',\n",
       " 'long_term_incentive': 1920000,\n",
       " 'other': 22122,\n",
       " 'poi': True,\n",
       " 'restricted_stock': 6843672,\n",
       " 'restricted_stock_deferred': 'NaN',\n",
       " 'salary': 1111258,\n",
       " 'shared_receipt_with_poi': 2042,\n",
       " 'to_messages': 3627,\n",
       " 'total_payments': 8682716,\n",
       " 'total_stock_value': 26093672}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What’s the value of stock options exercised by Jeffrey K Skilling?\n",
    "enron_data[\"SKILLING JEFFREY K\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8682716\n",
      "2424083\n",
      "103559793\n"
     ]
    }
   ],
   "source": [
    "# Of these three individuals (Lay, Skilling and Fastow), who took home the most money (largest value of “total_payments” feature)?\n",
    "print enron_data[\"SKILLING JEFFREY K\"]['total_payments']\n",
    "print enron_data[\"FASTOW ANDREW S\"]['total_payments']\n",
    "print enron_data[\"LAY KENNETH L\"]['total_payments']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "# How many folks in this dataset have a quantified salary? What about a known email address?\n",
    "count1 = 0\n",
    "count2 = 0 \n",
    "for p in enron_data:\n",
    "    for i in enron_data[p]:\n",
    "        if i == \"salary\":\n",
    "            temp1 = enron_data[p][i]\n",
    "            #print temp\n",
    "            if temp1 =='NaN':\n",
    "                pass\n",
    "            else:\n",
    "                count1 +=1\n",
    "        if i == \"email_address\":\n",
    "            temp2 = enron_data[p][i]\n",
    "            if temp2 =='NaN':\n",
    "                pass\n",
    "            else:\n",
    "                count2 +=1\n",
    "print count1\n",
    "print count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "    A general tool for converting data from the\n",
    "    dictionary format to an (n x k) python list that's \n",
    "    ready for training an sklearn algorithm\n",
    "\n",
    "    n--no. of key-value pairs in dictonary\n",
    "    k--no. of features being extracted\n",
    "\n",
    "    dictionary keys are names of persons in dataset\n",
    "    dictionary values are dictionaries, where each\n",
    "        key-value pair in the dict is the name\n",
    "        of a feature, and its value for that person\n",
    "\n",
    "    In addition to converting a dictionary to a numpy \n",
    "    array, you may want to separate the labels from the\n",
    "    features--this is what targetFeatureSplit is for\n",
    "\n",
    "    so, if you want to have the poi label as the target,\n",
    "    and the features you want to use are the person's\n",
    "    salary and bonus, here's what you would do:\n",
    "\n",
    "    feature_list = [\"poi\", \"salary\", \"bonus\"] \n",
    "    data_array = featureFormat( data_dictionary, feature_list )\n",
    "    label, features = targetFeatureSplit(data_array)\n",
    "\n",
    "    the line above (targetFeatureSplit) assumes that the\n",
    "    label is the _first_ item in feature_list--very important\n",
    "    that poi is listed first!\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def featureFormat( dictionary, features, remove_NaN=True, remove_all_zeroes=True, remove_any_zeroes=False, sort_keys = False):\n",
    "    \"\"\" convert dictionary to numpy array of features\n",
    "        remove_NaN = True will convert \"NaN\" string to 0.0\n",
    "        remove_all_zeroes = True will omit any data points for which\n",
    "            all the features you seek are 0.0\n",
    "        remove_any_zeroes = True will omit any data points for which\n",
    "            any of the features you seek are 0.0\n",
    "        sort_keys = True sorts keys by alphabetical order. Setting the value as\n",
    "            a string opens the corresponding pickle file with a preset key\n",
    "            order (this is used for Python 3 compatibility, and sort_keys\n",
    "            should be left as False for the course mini-projects).\n",
    "        NOTE: first feature is assumed to be 'poi' and is not checked for\n",
    "            removal for zero or missing values.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    return_list = []\n",
    "\n",
    "    # Key order - first branch is for Python 3 compatibility on mini-projects,\n",
    "    # second branch is for compatibility on final project.\n",
    "    if isinstance(sort_keys, str):\n",
    "        import pickle\n",
    "        keys = pickle.load(open(sort_keys, \"rb\"))\n",
    "    elif sort_keys:\n",
    "        keys = sorted(dictionary.keys())\n",
    "    else:\n",
    "        keys = dictionary.keys()\n",
    "\n",
    "    for key in keys:\n",
    "        tmp_list = []\n",
    "        for feature in features:\n",
    "            try:\n",
    "                dictionary[key][feature]\n",
    "            except KeyError:\n",
    "                print \"error: key \", feature, \" not present\"\n",
    "                return\n",
    "            value = dictionary[key][feature]\n",
    "            if value==\"NaN\" and remove_NaN:\n",
    "                value = 0\n",
    "            tmp_list.append( float(value) )\n",
    "\n",
    "        # Logic for deciding whether or not to add the data point.\n",
    "        append = True\n",
    "        # exclude 'poi' class as criteria.\n",
    "        if features[0] == 'poi':\n",
    "            test_list = tmp_list[1:]\n",
    "        else:\n",
    "            test_list = tmp_list\n",
    "        ### if all features are zero and you want to remove\n",
    "        ### data points that are all zero, do that here\n",
    "        if remove_all_zeroes:\n",
    "            append = False\n",
    "            for item in test_list:\n",
    "                if item != 0 and item != \"NaN\":\n",
    "                    append = True\n",
    "                    break\n",
    "        ### if any features for a given data point are zero\n",
    "        ### and you want to remove data points with any zeroes,\n",
    "        ### handle that here\n",
    "        if remove_any_zeroes:\n",
    "            if 0 in test_list or \"NaN\" in test_list:\n",
    "                append = False\n",
    "        ### Append the data point if flagged for addition.\n",
    "        if append:\n",
    "            return_list.append( np.array(tmp_list) )\n",
    "\n",
    "    return np.array(return_list)\n",
    "\n",
    "\n",
    "def targetFeatureSplit( data ):\n",
    "    \"\"\" \n",
    "        given a numpy array like the one returned from\n",
    "        featureFormat, separate out the first feature\n",
    "        and put it into its own list (this should be the \n",
    "        quantity you want to predict)\n",
    "\n",
    "        return targets and features as separate lists\n",
    "\n",
    "        (sklearn can generally handle both lists and numpy arrays as \n",
    "        input formats when training/predicting)\n",
    "    \"\"\"\n",
    "\n",
    "    target = []\n",
    "    features = []\n",
    "    for item in data:\n",
    "        target.append( item[0] )\n",
    "        features.append( item[1:] )\n",
    "\n",
    "    return target, features\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.0\n",
      "146.0\n",
      "14.3835616438\n"
     ]
    }
   ],
   "source": [
    "# How many people in the E+F dataset (as it currently exists) have “NaN” for their total payments? \n",
    "# What percentage of people in the dataset as a whole is this?\n",
    "count1 = 0 \n",
    "count2 = 0\n",
    "for p in enron_data:\n",
    "    count2 +=1\n",
    "    for i in enron_data[p]:\n",
    "        if i == \"total_payments\":\n",
    "            temp1 = enron_data[p][i]\n",
    "            #print temp\n",
    "            if temp1 =='NaN':\n",
    "                count1 +=1\n",
    "            else:\n",
    "                pass\n",
    "count1 = float(count1)\n",
    "count2 = float(count2)\n",
    "print count1\n",
    "print count2\n",
    "print (count1/count2)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288682\n",
      "1490344\n",
      "1099100\n",
      "2652612\n",
      "2003885\n",
      "4747979\n",
      "103559793\n",
      "2669589\n",
      "5501630\n",
      "2424083\n",
      "1639297\n",
      "505050\n",
      "8682716\n",
      "360300\n",
      "91093\n",
      "1587421\n",
      "1868758\n",
      "1272284\n",
      "18.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "count1 = 0 \n",
    "count2 = 0\n",
    "for p in enron_data:\n",
    "    for i in enron_data[p]:\n",
    "        if i == \"poi\":\n",
    "            temp1 = enron_data[p][i]\n",
    "            if temp1 == 1:\n",
    "                count1 +=1\n",
    "                print enron_data[p]['total_payments'] \n",
    "                if enron_data[p]['total_payments'] == 'NaN':\n",
    "                    enron_data[p]['total_payments']\n",
    "                    count2 +=1\n",
    "            else:\n",
    "                pass\n",
    "count1 = float(count1)\n",
    "count2 = float(count2)\n",
    "print count1\n",
    "print count2\n",
    "#print (count1/count2)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressions - Continuous Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Age/Net Worth Regression in sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# student Regression.py\n",
    "def studentReg(ages_train, net_worths_train):\n",
    "    ### import the sklearn regression module, create, and train your regression\n",
    "    ### name your regression reg\n",
    "    \n",
    "    ### your code goes here!\n",
    "    from sklearn import linear_model\n",
    "    reg = linear_model.LinearRegression()\n",
    "    reg.fit(ages_train,net_worths_train)\n",
    "    \n",
    "    \n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named ages_net_worths",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-cd23a7a08971>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mclass_vis\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprettyPicture\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_image\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mages_net_worths\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mageNetWorthData\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mages_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mages_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet_worths_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet_worths_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mageNetWorthData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named ages_net_worths"
     ]
    }
   ],
   "source": [
    "# StudentMain.py\n",
    "import numpy\n",
    "import matplotlib\n",
    "matplotlib.use('agg')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "#from studentRegression import studentReg\n",
    "from class_vis import prettyPicture, output_image\n",
    "\n",
    "from ages_net_worths import ageNetWorthData\n",
    "\n",
    "ages_train, ages_test, net_worths_train, net_worths_test = ageNetWorthData()\n",
    "\n",
    "\n",
    "\n",
    "reg = studentReg(ages_train, net_worths_train)\n",
    "\n",
    "\n",
    "plt.clf()\n",
    "plt.scatter(ages_train, net_worths_train, color=\"b\", label=\"train data\")\n",
    "plt.scatter(ages_test, net_worths_test, color=\"r\", label=\"test data\")\n",
    "plt.plot(ages_test, reg.predict(ages_test), color=\"black\")\n",
    "plt.legend(loc=2)\n",
    "plt.xlabel(\"ages\")\n",
    "plt.ylabel(\"net worths\")\n",
    "\n",
    "\n",
    "plt.savefig(\"test.png\")\n",
    "output_image(\"test.png\", \"png\", open(\"test.png\", \"rb\").read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# R^2 example\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
